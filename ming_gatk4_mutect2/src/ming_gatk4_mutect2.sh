#!/bin/bash
# ming_gatk4_mutect2 0.0.1
# Generated by dx-app-wizard.
#
# Basic execution pattern: Your app will run on a single machine from
# beginning to end.
#
# Your job's input variables (if any) will be loaded as environment
# variables before this script runs.  Any array inputs will be loaded
# as bash arrays.
#
# Any code outside of main() (or any entry point you may add) is
# ALWAYS executed, followed by running the entry point itself.
#
# See https://wiki.dnanexus.com/Developer-Portal for tutorials on how
# to modify this file.

main() {

    echo "Value of input: '${input[@]}'"

    # The following line(s) use the dx command-line tool to download your file
    # inputs to the local file system using variable names for the filenames. To
    # recover the original filenames, you can use the output of "dx describe
    # "$variable" --name".

#    for i in ${!input[@]}
#    do
#        dx download "${input[$i]}" -o input-$i
#    done

    mkdir -p /data/
    mkdir -p /data/in/
    mkdir -p /data/out/

    dx-download-all-inputs
    
    #remove all subfolder but keep files
    find in/ -type f -exec mv {} /data/in/ \;

    echo "# input files"   
    echo "$cmd_string"     
    ls -LR /data/in/
    ls /data/out/

    echo "# write variable into the cmd.sh"
    sed -i "1iReference=${Reference_name[0]}" /data/in/${cmd_sh_name[0]}
    sed -i "1itumor=${tumor_name[0]}" /data/in/${cmd_sh_name[0]}
    sed -i "1inormal=${normal_name[0]}" /data/in/${cmd_sh_name[0]}
    sed -i "1ipon=${pon_name[0]}" /data/in/${cmd_sh_name[0]}
    sed -i "1igermline_resource=${germline_resource_name[0]}" /data/in/${cmd_sh_name[0]}
    sed -i "1iList=${List_name[0]}" /data/in/${cmd_sh_name[0]}
    sed -i "1icommon_variant=${common_variant_name[0]}" /data/in/${cmd_sh_name[0]}
    sed -i "1ifunconator_data=${funconator_data_name[0]}" /data/in/${cmd_sh_name[0]}

    head /data/in/${cmd_sh_name[0]}

    chmod +x /data/in/${cmd_sh_name[0]}

    dx-docker run -v /data/:/gatk/data xmzhuo/genomic /gatk/data/in/${cmd_sh_name[0]} 

    echo "# gatk pipeline output"
    ls -LR /data/out/

    mkdir $HOME/out/

    mkdir $HOME/out/output/

    mv /data/out/* $HOME/out/output/

    echo "# files in output folder"

    ls -LR $HOME/out/
    dx-upload-all-outputs --parallel
    # Fill in your application code here.
    #
    # To report any recognized errors in the correct format in
    # $HOME/job_error.json and exit this script, you can use the
    # dx-jobutil-report-error utility as follows:
    #
    #   dx-jobutil-report-error "My error message"
    #
    # Note however that this entire bash script is executed with -e
    # when running in the cloud, so any line which returns a nonzero
    # exit code will prematurely exit the script; if no error was
    # reported in the job_error.json file, then the failure reason
    # will be AppInternalError with a generic error message.

    # The following line(s) use the utility dx-jobutil-add-output to format and
    # add output variables to your job's output as appropriate for the output
    # class.  Run "dx-jobutil-add-output -h" for more information on what it
    # does.

#    for i in "${!output[@]}"; do
#        dx-jobutil-add-output output "${output[$i]}" --class=array:file
#    done
}
